{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Conv3d layer input shape:\n",
    "# N -> number of sequences (mini batch)\n",
    "# Cin -> number of channels (3 for rgb)\n",
    "# D -> Number of images in a sequence\n",
    "# H -> Height of one image in the sequence\n",
    "# W -> Width of one image in the sequence\n",
    "\n",
    "\n",
    "import flash\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "from flash.image.classification.integrations.baal import ActiveLearningDataModule, ActiveLearningLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'vgg16' provided by PyTorch/torchvision (https://github.com/pytorch/vision).\n"
     ]
    }
   ],
   "source": [
    "head = nn.Sequential(\n",
    "            #nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            #nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n",
    "            #nn.Flatten(),\n",
    "            #nn.Linear(in_features=16384, out_features=4096),\n",
    "            #nn.ReLU(), \n",
    "            #nn.Dropout(0.25),\n",
    "            #nn.Linear(in_features=4096, out_features=256),\n",
    "            #nn.ReLU(), \n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(in_features=512, out_features=3),\n",
    "        )\n",
    "model = ImageClassifier(backbone=\"vgg16\", head=head, num_classes=3)\n",
    "model.adapter.backbone = model.adapter.backbone[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0007, -0.0125, -0.1118],\n",
       "        [ 0.0047, -0.0447, -0.1289],\n",
       "        [ 0.0510, -0.0130, -0.0777],\n",
       "        [ 0.0082, -0.0617, -0.0977],\n",
       "        [ 0.0290, -0.0455, -0.1132]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand((5, 64, 512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-3         [-1, 64, 128, 128]               0\n",
      "            Conv2d-4        [-1, 128, 128, 128]          73,856\n",
      "              ReLU-5        [-1, 128, 128, 128]               0\n",
      "            Conv2d-6        [-1, 128, 128, 128]         147,584\n",
      "              ReLU-7        [-1, 128, 128, 128]               0\n",
      "         MaxPool2d-8          [-1, 128, 64, 64]               0\n",
      "            Conv2d-9          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-10          [-1, 256, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-12          [-1, 256, 64, 64]               0\n",
      "           Conv2d-13          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-14          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-15          [-1, 256, 32, 32]               0\n",
      "           Conv2d-16          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-17          [-1, 512, 32, 32]               0\n",
      "           Conv2d-18          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-19          [-1, 512, 32, 32]               0\n",
      "           Conv2d-20          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-21          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-22          [-1, 512, 16, 16]               0\n",
      "           Conv2d-23          [-1, 512, 16, 16]       2,359,808\n",
      "             ReLU-24          [-1, 512, 16, 16]               0\n",
      "           Conv2d-25          [-1, 512, 16, 16]       2,359,808\n",
      "             ReLU-26          [-1, 512, 16, 16]               0\n",
      "           Conv2d-27          [-1, 512, 16, 16]       2,359,808\n",
      "             ReLU-28          [-1, 512, 16, 16]               0\n",
      "        MaxPool2d-29            [-1, 512, 8, 8]               0\n",
      "          Dropout-30                  [-1, 512]               0\n",
      "           Linear-31                    [-1, 3]           1,539\n",
      "================================================================\n",
      "Total params: 14,714,435\n",
      "Trainable params: 14,714,435\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 16.00\n",
      "Forward/backward pass size (MB): 221.25\n",
      "Params size (MB): 56.13\n",
      "Estimated Total Size (MB): 293.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "#from src.models.conv_net import MedicalNet\n",
    "#model = MedicalNet(path_to_weights=\"resnet_10.pth\", device=\"cuda\")\n",
    "model.cuda()\n",
    "summary(model.adapter, (64, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Bastian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3361: FutureWarning: Please pass an instantiated object of the `InputTransform` class. Passing the Class and keyword arguments separately has been deprecated since v0.8.0 and will be removed in v0.9.0.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomFileDataset' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m flash\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m \u001b[43mActiveLearningDataModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_datset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_num_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flash\\image\\classification\\integrations\\baal\\data.py:92\u001b[0m, in \u001b[0;36mActiveLearningDataModule.__init__\u001b[1;34m(self, labelled, heuristic, map_dataset_to_labelled, filter_unlabelled_data, initial_num_labels, query_size, val_split)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabelled:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe labelled `datamodule` should be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabelled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe labelled dataset should be labelled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabelled \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabelled\u001b[38;5;241m.\u001b[39m_val_input \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabelled\u001b[38;5;241m.\u001b[39m_predict_input):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomFileDataset' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "trainer = flash.Trainer(max_epochs=3)\n",
    "datamodule = ActiveLearningDataModule(\n",
    "    train_datset,\n",
    "    initial_num_labels=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, \"..\") \n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_all(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP sample len 1496\n",
      "NCP sample len 1218\n",
      "Normal sample len 472\n",
      "size train files: 990\n",
      "size test files: 282\n",
      "size val files: 141\n",
      "size initial pool files: 3\n"
     ]
    }
   ],
   "source": [
    "import src.visualization.utils as vis\n",
    "from torchvision import transforms\n",
    "from src.dataset.dataset import CustomDataset, CustomFileDataset, collate_fn_padd\n",
    "from src.dataset.utils import get_active_learning_datasets, MyRotationTransform\n",
    "import torch\n",
    "\n",
    "seed_all(123)\n",
    "\n",
    "dataset = CustomDataset(data_path=\"../data/NPY/volumes/\",\n",
    "                             target_path=\"../data/NPY/labels/\")\n",
    "train_indices, val_indices, test_indices, _= get_active_learning_datasets(dataset, split=[0.7, 0.1, 0.2])\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize(512//2),\n",
    "                                        transforms.RandomVerticalFlip(),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.1), scale=(0.5, 0.75)),\n",
    "                                        #transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "                                      ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(512),\n",
    "                                    ])\n",
    "train_datset = CustomFileDataset([dataset.data_paths[idx] for idx in list(train_indices)],\n",
    "                                        [dataset.targets[idx] for idx in list(train_indices)],\n",
    "                                            train_transform)\n",
    "\n",
    "test_datset = CustomFileDataset([dataset.data_paths[idx] for idx in list(train_indices)],\n",
    "                                        [dataset.targets[idx] for idx in list(train_indices)],\n",
    "                                            train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_module = ActiveLearningDataModule(initial_num_labels=5, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_datset,\n",
    "                            num_workers=4,\n",
    "                            batch_size=2,\n",
    "                            pin_memory=True,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=collate_fn_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0]\n",
    "print(img.shape)\n",
    "label = train_labels[0]\n",
    "vis.plot_from_volume_tensor(img, label, n_samples=10)\n",
    "print(f\"Label: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ba41da815aa047041a42bb235514dd275a168b3f2f58893abf50244d8fb0ae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
